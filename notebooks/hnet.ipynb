{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2c0lF4kjpeX"
      },
      "source": [
        "**HNet** stands for ***graphical Hypergeometric Networks***, which is a method where associations across variables are tested for significance by statistical inference.\n",
        "\n",
        "Real-world data often contain measurements with both continuous and discrete values. Despite the availability of many libraries, data sets with mixed data types require intensive pre-processing steps, and it remains a challenge to describe the relationships between variables. The data understanding phase is crucial to the data-mining process, however, without making any assumptions on the data, the search space is super-exponential in the number of variables. A thorough data understanding phase is therefore not common practice.\n",
        "\n",
        "The **aim** is to determine a network with significant associations that can shed light on the complex relationships across variables. Input datasets can range from generic dataframes to nested data structures with lists, missing values and enumerations.\n",
        "\n",
        "* [API Documentation](https://erdogant.github.io/hnet/)\n",
        "* [Article]( https://arxiv.org/abs/2005.04679)\n",
        "* [Github]( https://github.com/erdogant/hnet)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH5Lq4KajjF1"
      },
      "source": [
        "!pip install hnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSd_ofaejlEt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hnet import hnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCE9Rm-5zYEH"
      },
      "source": [
        "# Import example dataset\n",
        "\n",
        "There are various options that can be downloaded using hnet.\n",
        "* 'sprinkler'\n",
        "* 'titanic'\n",
        "* 'student'\n",
        "* 'fifa'\n",
        "* 'cancer'\n",
        "* 'waterpump'\n",
        "* 'retail'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGDLiL1ZkLl0"
      },
      "source": [
        "hn = hnet()\n",
        "df = hn.import_example(data='titanic')\n",
        "\n",
        "# Removing variables for which I know that will not contribute in the model.\n",
        "del df['PassengerId']\n",
        "del df['Name']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9Zlj_R_GJqS"
      },
      "source": [
        "# Initialize model with default parameters\n",
        "hn = hnet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLPqI8eWGaC5"
      },
      "source": [
        "==============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELxsRkYc1aWO"
      },
      "source": [
        "## Import data from url\n",
        "\n",
        "***HNet*** allows direct downloads from the internet using a url-link. As an example, the [UCI](https://archive.ics.uci.edu/ml/) website is a huge *machine learning data repository*. Lets automatically download and import a datset from UCI website. Note that **not** all datasets can be used. The data needs to be in a csv format (not json), and the datasets needs to have at least 1 categorical variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHY-kgVx1XCK"
      },
      "source": [
        "# Import dataset from website\n",
        "url='https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "\n",
        "df = hn.import_example(url=url)\n",
        "# Add column names\n",
        "df.columns=['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','earnings']\n",
        "# Set the following columns as floating type\n",
        "cols_as_float = ['age','hours-per-week','capital-loss','capital-gain']\n",
        "df[cols_as_float]=df[cols_as_float].astype(float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VafJhfE04HFt"
      },
      "source": [
        "# Lets examine the dataset wether the columns are set correctly and the variable name matches the items.\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxKnPgPW3g7h"
      },
      "source": [
        "# Initialize model with variable fnlwgt in the black-list. This means that it is not included in the modelling. \n",
        "hn = hnet(black_list=['fnlwgt'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZQcnnb6GTSK"
      },
      "source": [
        "==============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkWafOEoGeDg"
      },
      "source": [
        "### Association learning using **HNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlxkKSIW37tG"
      },
      "source": [
        "# Learn its associations\n",
        "results = hn.association_learning(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poDcyeFOlf9u"
      },
      "source": [
        "# All the results are stored in results\n",
        "print(results.keys())\n",
        "\n",
        "# The results are accesable by using the keys.\n",
        "\n",
        "#results['labx']\n",
        "\n",
        "#results['counts']\n",
        "\n",
        "#results['simmatLogP']\n",
        "\n",
        "#results['dtypes']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkTR_qFG6TWd"
      },
      "source": [
        "## Plotting \n",
        "\n",
        "There are many possibilities regarding plotting the results. \n",
        "There are ***static*** plots, and ***dynamic*** plots. In case of using colab, the dynamic plots will not work as it requires writing d3-javascript files to disk. The following functions are available for plotting:\n",
        "\n",
        "#### Network-graph\n",
        "* hn.plot()\n",
        "* hn.d3graph()\n",
        "\n",
        "#### Heatmap\n",
        "* hn.heatmap()\n",
        "* hn.d3heatmap()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmeKk_jQlrbL"
      },
      "source": [
        "# Lets plot a static network\n",
        "\n",
        "# If the network looks like a big hairball, try to play with some of the following parameters:\n",
        "ax = hn.plot(scale=1, dpi=100, figsize=(15,15))\n",
        "# ax = hn.plot(scale=10, dist_between_nodes=2, figsize=(20,20), dpi=400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uh-g_xxl53N"
      },
      "source": [
        "# Make the network plot interactive with d3-javascript\n",
        "out = hn.d3graph()\n",
        "\n",
        "# Download files and open locally it does not open automatically:\n",
        "print(out['path'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0_5iGnX9pp1"
      },
      "source": [
        "# Plot the heatmap\n",
        "\n",
        "# Plot the heatmap without ordering:\n",
        "ax = hn.heatmap(figsize=(10,10))\n",
        "\n",
        "# Cluster the heatmap:\n",
        "ax = hn.heatmap(cluster=True, figsize=(10,10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ibILgnH2cO"
      },
      "source": [
        "# Plot the heatmap in d3-javascript\n",
        "\n",
        "# Plot the heatmap without ordering:\n",
        "ax = hn.d3heatmap()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUqEl1sYmIfC",
        "outputId": "9e888f40-df9a-4772-f0a4-74d245f88fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Save the resuls\n",
        "savepath=hn.save(overwrite=True)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[pypickle] Pickle file saved: [hnet_model.pkl]\n",
            "[hnet] >Saving.. True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE8rFORTvieg",
        "outputId": "238aeea1-8cc1-43b4-b60a-7053c4da80f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "dir(hn)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_check_results',\n",
              " 'alpha',\n",
              " 'association_learning',\n",
              " 'black_list',\n",
              " 'combined_rules',\n",
              " 'compute_associations',\n",
              " 'd3graph',\n",
              " 'd3heatmap',\n",
              " 'dropna',\n",
              " 'dtypes',\n",
              " 'excl_background',\n",
              " 'fillna',\n",
              " 'heatmap',\n",
              " 'import_example',\n",
              " 'k',\n",
              " 'load',\n",
              " 'multtest',\n",
              " 'perc_min_num',\n",
              " 'plot',\n",
              " 'prepocessing',\n",
              " 'results',\n",
              " 'save',\n",
              " 'specificity',\n",
              " 'white_list',\n",
              " 'y_min']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}